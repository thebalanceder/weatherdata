{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cb55321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightning in c:\\users\\user-pc\\anaconda3\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: pytorch-lightning in c:\\users\\user-pc\\anaconda3\\lib\\site-packages (from lightning) (2.1.0)\n",
      "Requirement already satisfied: fsspec[http]<2025.0,>2021.06.0 in c:\\users\\user-pc\\anaconda3\\lib\\site-packages (from lightning) (2022.11.0)\n",
      "Requirement already satisfied: typing-extensions<6.0,>=4.0.0 in c:\\users\\user-pc\\anaconda3\\lib\\site-packages (from lightning) (4.4.0)\n",
      "Requirement already satisfied: PyYAML<8.0,>=5.4 in c:\\users\\user-pc\\anaconda3\\lib\\site-packages (from lightning) (6.0)\n",
      "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in c:\\users\\user-pc\\anaconda3\\lib\\site-packages (from lightning) (1.2.0)\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in c:\\users\\user-pc\\anaconda3\\lib\\site-packages (from lightning) (4.64.1)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.8.0 in c:\\users\\user-pc\\anaconda3\\lib\\site-packages (from lightning) (0.9.0)\n",
      "Requirement already satisfied: torch<4.0,>=1.12.0 in c:\\users\\user-pc\\anaconda3\\lib\\site-packages (from lightning) (1.12.1)\n",
      "Requirement already satisfied: numpy<3.0,>=1.17.2 in c:\\users\\user-pc\\anaconda3\\lib\\site-packages (from lightning) (1.23.5)\n",
      "Requirement already satisfied: packaging<25.0,>=20.0 in c:\\users\\user-pc\\anaconda3\\lib\\site-packages (from lightning) (22.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\user-pc\\anaconda3\\lib\\site-packages (from fsspec[http]<2025.0,>2021.06.0->lightning) (3.8.6)\n",
      "Requirement already satisfied: requests in c:\\users\\user-pc\\anaconda3\\lib\\site-packages (from fsspec[http]<2025.0,>2021.06.0->lightning) (2.28.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user-pc\\anaconda3\\lib\\site-packages (from tqdm<6.0,>=4.57.0->lightning) (0.4.6)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user-pc\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (6.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user-pc\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\user-pc\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (2.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\user-pc\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\user-pc\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user-pc\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\user-pc\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>2021.06.0->lightning) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user-pc\\anaconda3\\lib\\site-packages (from requests->fsspec[http]<2025.0,>2021.06.0->lightning) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user-pc\\anaconda3\\lib\\site-packages (from requests->fsspec[http]<2025.0,>2021.06.0->lightning) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user-pc\\anaconda3\\lib\\site-packages (from requests->fsspec[http]<2025.0,>2021.06.0->lightning) (3.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74cbb950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightning as L\n",
    "from torch.utils.data import TensorDataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1bc9742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('iaq_middle5.csv')\n",
    "column_name = 'Humidnity'\n",
    "\n",
    "data_array = df[column_name].values\n",
    "obs=data_array[:-1]\n",
    "scaled_obs = obs * 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cff086eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data set declaration \n",
    "A=1.0\n",
    "B=2.0\n",
    "C=3.0\n",
    "D=4.0\n",
    "pred_E=5.0\n",
    "\n",
    "Z=0.06\n",
    "G=0.07\n",
    "H=0.08\n",
    "I=0.09\n",
    "pred_J=0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbdfc796",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMbyHand(L.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        mean=torch.tensor(0.0)\n",
    "        std=torch.tensor(1.0)\n",
    "        \n",
    "        self.wlr1=nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n",
    "        self.wlr2=nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n",
    "        self.blr1=nn.Parameter(torch.tensor(0.0),requires_grad=True)\n",
    "        self.wpr1=nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n",
    "        self.wpr2=nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n",
    "        self.bpr1=nn.Parameter(torch.tensor(0.0),requires_grad=True)\n",
    "        self.wp1=nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n",
    "        self.wp2=nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n",
    "        self.bp1=nn.Parameter(torch.tensor(0.0),requires_grad=True)\n",
    "        self.wo1=nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n",
    "        self.wo2=nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n",
    "        self.bo1=nn.Parameter(torch.tensor(0.0),requires_grad=True)\n",
    "        \n",
    "    def lstm_unit(self,input_value,long_memory,short_memory):\n",
    "        long_remember_percent=torch.sigmoid((short_memory*self.wlr1)+(input_value*self.wlr2)+self.blr1)\n",
    "        potential_remember_memory=torch.sigmoid((short_memory*self.wpr1)+(input_value*self.wpr2)+self.bpr1)\n",
    "        potential_memory=torch.tanh((short_memory*self.wp1)+(input_value*self.wp2)+self.bp1)\n",
    "        updated_long_memory=((long_memory*long_remember_percent)+(potential_remember_memory*potential_memory))\n",
    "        output_percent=torch.sigmoid((short_memory*self.wo1)+(input_value*self.wo2)+self.bo1)\n",
    "        updated_short_memory=torch.tanh(updated_long_memory)*output_percent\n",
    "        return([updated_long_memory,updated_short_memory])\n",
    "    \n",
    "    def forward(self,input):\n",
    "        long_memory=0\n",
    "        short_memory=0\n",
    "        \n",
    "        indices = list(range(0, len(scaled_obs)))\n",
    "        \n",
    "        for index in indices:\n",
    "            element = input[index]  # Access the element using tensor indexing\n",
    "            long_memory, short_memory = self.lstm_unit(element, long_memory, short_memory)\n",
    "        \n",
    "        return short_memory\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        return optimizer\n",
    "    \n",
    "    def training_step(self,batch,batch_idx):\n",
    "        input_i,label_i=batch\n",
    "        output_i=self.forward(input_i[0])\n",
    "        loss=(output_i-label_i)**2\n",
    "        self.log(\"train_loss\",loss)\n",
    "        \n",
    "        if (label_i==0):\n",
    "            self.log(\"output_0\",output_i)\n",
    "        \n",
    "        else:\n",
    "            self.log(\"output_1\",output_i)\n",
    "        return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "801e8c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Suppose you have a list of NumPy arrays named numpy_array_list\n",
    "numpy_array_list = [np.array([1, 2, 3]), np.array([4, 5, 6]), np.array([7, 8, 9])]\n",
    "\n",
    "# Convert the list of NumPy arrays into a single NumPy array\n",
    "combined_numpy_array = np.concatenate(numpy_array_list)\n",
    "\n",
    "# Convert the combined NumPy array into a PyTorch tensor\n",
    "tensor = torch.tensor(combined_numpy_array)\n",
    "\n",
    "# Now, 'tensor' contains the data in a PyTorch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "250e9826",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company A, observed=0,predicted: tensor(0.0257, dtype=torch.float64, grad_fn=<MulBackward0>)\n",
      "Company B, observed=0,predicted: tensor(0.0257, dtype=torch.float64, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model=LSTMbyHand()\n",
    "print(\"Company A, observed=0,predicted:\",model(torch.tensor(scaled_obs).detach()))\n",
    "print(\"Company B, observed=0,predicted:\",model(torch.tensor(scaled_obs).detach()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41048fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER-PC\\AppData\\Local\\Temp\\ipykernel_5016\\156531037.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  C:\\b\\abs_bao0hdcrdh\\croot\\pytorch_1675190257512\\work\\torch\\csrc\\utils\\tensor_new.cpp:204.)\n",
      "  inputs=torch.tensor([scaled_obs])\n"
     ]
    }
   ],
   "source": [
    "inputs=torch.tensor([scaled_obs])\n",
    "#[A,B,C,D],[Z,G,H,I]\n",
    "labels=torch.tensor([data_array[-1]*0.001])\n",
    "#pred_E,pred_J\n",
    "\n",
    "dataset=TensorDataset(inputs,labels)\n",
    "dataloader=DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a4a76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name         | Type | Params\n",
      "--------------------------------------\n",
      "  | other params | n/a  | 12    \n",
      "--------------------------------------\n",
      "12        Trainable params\n",
      "0         Non-trainable params\n",
      "12        Total params\n",
      "0.000     Total estimated model params size (MB)\n",
      "C:\\Users\\USER-PC\\anaconda3\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\USER-PC\\anaconda3\\lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:293: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16d87362b5014aec8520358b05915dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer=L.Trainer(max_epochs=500)\n",
    "trainer.fit(model,train_dataloaders=dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f741072",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_to_best_checkpoint=trainer.checkpoint_callback.best_model_path\n",
    "trainer=L.Trainer(max_epochs=510)\n",
    "trainer.fit(model,train_dataloaders=dataloader,ckpt_path=path_to_best_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d520b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction1=model(torch.tensor(scaled_obs).detach())\n",
    "\n",
    "print(\"Company A, observed=0,predicted:\",prediction1*1000)\n",
    "print(\"Company B, observed=0,predicted:\",prediction1*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714cf6f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
